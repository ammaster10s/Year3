{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ammaster10s/Year3/blob/main/Evaluate_OCT_NV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RJuV09tc4hX",
    "outputId": "3914d821-4ea9-4300-98c9-9df865e6fdff"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hu9RQe83c1U0",
    "outputId": "701f2866-49f9-443d-a90a-946124190b7d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "from pycocotools import mask as maskUtils\n",
    "import json\n",
    "from tensorflow import keras\n",
    "from keras import backend as KK  # Import Keras backend\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend\n",
    "\n",
    "# Load the pretrained U-Net model\n",
    "# Load the model and pass K as a custom object\n",
    "model_path = '/content/drive/MyDrive/Working/models/attention_unet_model_62epoch_423_4.h5'\n",
    "unet_model = load_model(model_path)\n",
    "# unet_model = load_model(model_path)\n",
    "\n",
    "# Load and preprocess the full image for prediction\n",
    "def load_full_image(image_path, target_size=(256, 256)):\n",
    "    full_image = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
    "    full_image_array = img_to_array(full_image) / 255.0\n",
    "    full_image_array = np.expand_dims(full_image_array, axis=0)  # Add batch dimension\n",
    "    return full_image_array\n",
    "\n",
    "# Function to handle both RLE and polygon segmentation formats in COCO\n",
    "def segmentation_to_mask(segmentation, width, height):\n",
    "    if isinstance(segmentation, dict):  # RLE format (compressed RLE)\n",
    "        # print(\"Decoding RLE mask\")\n",
    "        rle = maskUtils.frPyObjects(segmentation, height, width)\n",
    "        mask = maskUtils.decode(rle)\n",
    "        return mask\n",
    "    elif isinstance(segmentation, list):  # Polygon format\n",
    "        # print(\"Processing polygon mask\")\n",
    "        mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        # Create a binary mask from polygons\n",
    "        for polygon in segmentation:\n",
    "            poly = np.array(polygon).reshape((-1, 2))\n",
    "            img = Image.new('L', (width, height), 0)\n",
    "            ImageDraw.Draw(img).polygon([tuple(p) for p in poly], outline=1, fill=1)\n",
    "            mask = np.array(img, dtype=np.uint8)\n",
    "        return mask\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported segmentation format\")\n",
    "\n",
    "# Function to parse the COCO JSON file and return annotations\n",
    "def parse_coco_json(json_file, image_dir):\n",
    "    with open(json_file, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    annotations = []\n",
    "    image_data = {}\n",
    "\n",
    "    # Map image ID to file name and other metadata\n",
    "    for img_info in coco_data['images']:\n",
    "        image_data[img_info['id']] = {\n",
    "            'file_name': img_info['file_name'],\n",
    "            'width': img_info['width'],\n",
    "            'height': img_info['height']\n",
    "        }\n",
    "\n",
    "    # Extract segmentation and mask information\n",
    "    for ann in coco_data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        image_info = image_data[image_id]\n",
    "        image_filename = image_info['file_name']\n",
    "        width = image_info['width']\n",
    "        height = image_info['height']\n",
    "\n",
    "        # Get the segmentation mask (COCO format supports RLE or polygons)\n",
    "        mask = segmentation_to_mask(ann['segmentation'], width, height)\n",
    "\n",
    "        annotations.append((image_filename, mask))\n",
    "\n",
    "    return annotations\n",
    "\n",
    "# Function to compute IoU (Intersection over Union)\n",
    "def compute_iou(predicted_mask, ground_truth_mask):\n",
    "    # Flatten masks to compute IoU on 1D arrays\n",
    "    predicted_mask = predicted_mask.flatten()\n",
    "    ground_truth_mask = ground_truth_mask.flatten()\n",
    "\n",
    "    # Compute IoU\n",
    "    intersection = np.sum(np.logical_and(predicted_mask, ground_truth_mask))\n",
    "    union = np.sum(np.logical_or(predicted_mask, ground_truth_mask))\n",
    "    iou = intersection / union if union != 0 else 0\n",
    "\n",
    "    return iou\n",
    "\n",
    "# Function to compute Dice coefficient\n",
    "def compute_dice(predicted_mask, ground_truth_mask):\n",
    "    # Flatten masks\n",
    "    predicted_mask = predicted_mask.flatten()\n",
    "    ground_truth_mask = ground_truth_mask.flatten()\n",
    "\n",
    "    # Compute Dice Coefficient\n",
    "    intersection = np.sum(np.logical_and(predicted_mask, ground_truth_mask))\n",
    "    dice = (2. * intersection) / (np.sum(predicted_mask) + np.sum(ground_truth_mask))\n",
    "\n",
    "    return dice\n",
    "\n",
    "# Function to evaluate the model on each image and mask from COCO annotations\n",
    "def evaluate_model_on_coco(test_dir, coco_json_file, threshold=0.5):\n",
    "    iou_scores = []\n",
    "    dice_scores = []\n",
    "    annotations = parse_coco_json(coco_json_file, test_dir)\n",
    "    counter = 0\n",
    "\n",
    "    # Loop through all images and masks from COCO annotations\n",
    "    for image_filename, ground_truth_mask in annotations:\n",
    "        full_image_path = os.path.join(test_dir, image_filename)\n",
    "\n",
    "        if not os.path.exists(full_image_path):\n",
    "            # print(f\"Image {image_filename} not found, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        full_image = load_full_image(full_image_path)\n",
    "\n",
    "        # Predict the mask for the full image\n",
    "        predicted_mask = unet_model.predict(full_image)[0, :, :, 0]  # Extract the 2D mask\n",
    "\n",
    "        # Apply threshold to convert the predicted mask to binary\n",
    "        predicted_mask_binary = (predicted_mask > threshold).astype(np.uint8)\n",
    "\n",
    "        # Resize the ground truth mask to match the predicted mask size\n",
    "        ground_truth_mask_resized = np.array(Image.fromarray(ground_truth_mask).resize((256, 256), Image.NEAREST))\n",
    "\n",
    "        # Calculate IoU and Dice scores\n",
    "        iou = compute_iou(predicted_mask_binary, ground_truth_mask_resized)\n",
    "        dice = compute_dice(predicted_mask_binary, ground_truth_mask_resized)\n",
    "\n",
    "        iou_scores.append(iou)\n",
    "        dice_scores.append(dice)\n",
    "\n",
    "        # Display evaluation results\n",
    "        print(f\"{image_filename}: IoU = {iou}, Dice Coefficient = {dice}\")\n",
    "\n",
    "        # Optionally plot every 10th result\n",
    "        # Optionally plot every 10th result\n",
    "        if counter % 10 == 0:\n",
    "            plt.figure(figsize=(16, 8))  # Adjusting the figure size for four subplots\n",
    "\n",
    "            # Subplot 1: Display the original full image\n",
    "            plt.subplot(1, 4, 1)\n",
    "            plt.imshow(np.squeeze(full_image), cmap='gray')\n",
    "            plt.title(f'Full Image: {image_filename}')\n",
    "\n",
    "            # Subplot 2: Display the predicted NV mask heatmap\n",
    "            plt.subplot(1, 4, 2)\n",
    "            plt.imshow(predicted_mask, cmap='jet', alpha=0.6)\n",
    "            plt.title('Predicted NV Heatmap')\n",
    "            plt.colorbar()\n",
    "\n",
    "            # Subplot 3: Overlay predicted mask on the full image\n",
    "            plt.subplot(1, 4, 3)\n",
    "            plt.imshow(np.squeeze(full_image), cmap='gray')  # Original image\n",
    "            plt.imshow(predicted_mask_binary, cmap='jet', alpha=0.5)  # Predicted mask overlay\n",
    "            plt.title('Overlay: Full Image with Predicted Mask')\n",
    "\n",
    "            # Subplot 4: Display the ground truth mask\n",
    "            plt.subplot(1, 4, 4)\n",
    "            plt.imshow(ground_truth_mask_resized, cmap='gray')\n",
    "            plt.title('Ground Truth Mask')\n",
    "\n",
    "            # Show the plots\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    # Print average metrics\n",
    "    print(f\"Average IoU: {np.mean(iou_scores)}\")\n",
    "    print(f\"Average Dice Coefficient: {np.mean(dice_scores)}\")\n",
    "\n",
    "# Paths to your dataset (Images and COCO annotations)\n",
    "test_image_dir = '/content/drive/MyDrive/Working/train/CNV'\n",
    "test_json_annotation_file = '/content/drive/MyDrive/Working/train/instances_default.json'  # COCO JSON file with annotations\n",
    "\n",
    "# Run the evaluation\n",
    "evaluate_model_on_coco(test_image_dir, test_json_annotation_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIk0vL3ZedcK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "from pycocotools import mask as maskUtils\n",
    "import json\n",
    "import tensorflow as tf # Import tensorflow\n",
    "\n",
    "\n",
    "model_path = '/content/drive/MyDrive/Working/models/attention_unet_model_62epoch_423_4.h5'\n",
    "unet_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Load and preprocess the full image for prediction\n",
    "def load_full_image(image_path, target_size=(256, 256)):\n",
    "    full_image = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
    "    full_image_array = img_to_array(full_image) / 255.0\n",
    "    full_image_array = np.expand_dims(full_image_array, axis=0)  # Add batch dimension\n",
    "    return full_image_array\n",
    "\n",
    "# Function to handle both RLE and polygon segmentation formats in COCO\n",
    "def segmentation_to_mask(segmentation, width, height):\n",
    "    if isinstance(segmentation, dict):  # RLE format (compressed RLE)\n",
    "        print(\"Decoding RLE mask\")\n",
    "        rle = maskUtils.frPyObjects(segmentation, height, width)\n",
    "        mask = maskUtils.decode(rle)\n",
    "        return mask\n",
    "    elif isinstance(segmentation, list):  # Polygon format\n",
    "        print(\"Processing polygon mask\")\n",
    "        mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        # Create a binary mask from polygons\n",
    "        for polygon in segmentation:\n",
    "            poly = np.array(polygon).reshape((-1, 2))\n",
    "            img = Image.new('L', (width, height), 0)\n",
    "            ImageDraw.Draw(img).polygon([tuple(p) for p in poly], outline=1, fill=1)\n",
    "            mask = np.array(img, dtype=np.uint8)\n",
    "        return mask\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported segmentation format\")\n",
    "\n",
    "# Function to parse the COCO JSON file and return annotations\n",
    "def parse_coco_json(json_file, image_dir):\n",
    "    with open(json_file, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    annotations = []\n",
    "    image_data = {}\n",
    "\n",
    "    # Map image ID to file name and other metadata\n",
    "    for img_info in coco_data['images']:\n",
    "        image_data[img_info['id']] = {\n",
    "            'file_name': img_info['file_name'],\n",
    "            'width': img_info['width'],\n",
    "            'height': img_info['height']\n",
    "        }\n",
    "\n",
    "    # Extract segmentation and mask information\n",
    "    for ann in coco_data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        image_info = image_data[image_id]\n",
    "        image_filename = image_info['file_name']\n",
    "        width = image_info['width']\n",
    "        height = image_info['height']\n",
    "\n",
    "        # Get the segmentation mask (COCO format supports RLE or polygons)\n",
    "        mask = segmentation_to_mask(ann['segmentation'], width, height)\n",
    "\n",
    "        annotations.append((image_filename, mask))\n",
    "\n",
    "    return annotations\n",
    "\n",
    "# Function to evaluate if the predicted mask correctly matches the ground truth\n",
    "def evaluate_prediction_accuracy(predicted_mask, ground_truth_mask, threshold=0.5):\n",
    "    # Apply threshold to predicted mask\n",
    "    predicted_mask_binary = (predicted_mask > threshold).astype(np.uint8)\n",
    "\n",
    "    # Check if predicted mask overlaps with ground truth (1 where predicted, 1 where ground truth)\n",
    "    # Correct pixels = intersection of predicted and ground truth\n",
    "    correct_pixels = np.sum(np.logical_and(predicted_mask_binary, ground_truth_mask))\n",
    "\n",
    "    # Return 1 if there are any correct pixels, else 0\n",
    "    return 1 if correct_pixels > 0 else 0\n",
    "\n",
    "# Function to evaluate the model on each image and mask from COCO annotations\n",
    "def evaluate_model_on_coco(test_dir, coco_json_file, threshold=0.5):\n",
    "    total_images = 0\n",
    "    total_correct = 0\n",
    "    annotations = parse_coco_json(coco_json_file, test_dir)\n",
    "\n",
    "    # Loop through all images and masks from COCO annotations\n",
    "    for image_filename, ground_truth_mask in annotations:\n",
    "        full_image_path = os.path.join(test_dir, image_filename)\n",
    "\n",
    "        if not os.path.exists(full_image_path):\n",
    "            print(f\"Image {image_filename} not found, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        full_image = load_full_image(full_image_path)\n",
    "\n",
    "        # Predict the mask for the full image\n",
    "        predicted_mask = unet_model.predict(full_image)[0, :, :, 0]  # Extract the 2D mask\n",
    "\n",
    "        # predicted_mask = model.predict(full_image)[0, :, :, 0]  # Extract the 2D mask\n",
    "\n",
    "        # Resize the ground truth mask to match the predicted mask size\n",
    "        ground_truth_mask_resized = np.array(Image.fromarray(ground_truth_mask).resize((256, 256), Image.NEAREST))\n",
    "\n",
    "        # Evaluate the prediction correctness\n",
    "        is_correct = evaluate_prediction_accuracy(predicted_mask, ground_truth_mask_resized, threshold)\n",
    "\n",
    "        total_images += 1\n",
    "        total_correct += is_correct\n",
    "\n",
    "        # Display evaluation results\n",
    "        print(f\"{image_filename}: Prediction Correct: {is_correct}\")\n",
    "\n",
    "    # Print final accuracy\n",
    "    accuracy = total_correct / total_images if total_images > 0 else 0\n",
    "    print(f\"Total Correct: {total_correct}/{total_images}\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Paths to your dataset (Images and COCO annotations)\n",
    "test_image_dir = '/content/drive/MyDrive/Working/val/CNV35'\n",
    "test_json_annotation_file = '/content/drive/MyDrive/Working/val/instances_default.json'  # COCO JSON file with annotations\n",
    "\n",
    "# Run the evaluation\n",
    "evaluate_model_on_coco(test_image_dir, test_json_annotation_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrVL8uE3AMkb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load and preprocess the full image for prediction\n",
    "def load_full_image(image_path, target_size=(256, 256)):\n",
    "    full_image = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
    "    full_image_array = img_to_array(full_image) / 255.0\n",
    "    full_image_array = np.expand_dims(full_image_array, axis=0)\n",
    "    return full_image_array\n",
    "\n",
    "# Load your model\n",
    "loaded_model = load_model('/content/drive/MyDrive/Working/models/attention_unet_model_62epoch_423_4.h5')\n",
    "\n",
    "# Directory path containing the images to test\n",
    "test_dir = '/content/drive/MyDrive/Working/Test/Mix'\n",
    "\n",
    "# Get list of image files and shuffle them randomly\n",
    "image_files = [f for f in os.listdir(test_dir) if f.endswith(('.jpeg', '.jpg', '.png'))]\n",
    "random.shuffle(image_files)  # Shuffle the list randomly\n",
    "\n",
    "# Loop through the shuffled image files and display results\n",
    "for image_filename in image_files:\n",
    "    full_image_path = os.path.join(test_dir, image_filename)\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    full_image = load_full_image(full_image_path)\n",
    "\n",
    "    # Predict the mask for the full image\n",
    "    predicted_mask = loaded_model.predict(full_image)[0, :, :, 0]  # Extract the 2D mask\n",
    "\n",
    "    # Apply threshold to get a binary mask\n",
    "    threshold = 0.5\n",
    "    predicted_mask_binary = (predicted_mask > threshold).astype(np.uint8)\n",
    "\n",
    "    # Plot the results for each image\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Display the original full image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(np.squeeze(full_image), cmap='gray')\n",
    "    plt.title(f'Full Image: {image_filename}')\n",
    "\n",
    "    # Display the predicted NV mask heatmap\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(predicted_mask, cmap='jet', alpha=0.6)\n",
    "    plt.title('Predicted NV Heatmap')\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Overlay predicted mask on the full image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(np.squeeze(full_image), cmap='gray')  # Original image\n",
    "    plt.imshow(predicted_mask_binary, cmap='jet', alpha=0.5)  # Predicted mask overlay\n",
    "    plt.title('Overlay: Full Image with Predicted Mask')\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwYJQ3b3CPuC",
    "outputId": "f97c4762-b5f3-46d5-c3e3-62810f48836c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Load and preprocess the full image for prediction\n",
    "def load_full_image(image_path, target_size=(256, 256)):\n",
    "    full_image = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
    "    full_image_array = img_to_array(full_image) / 255.0\n",
    "    full_image_array = np.expand_dims(full_image_array, axis=0)\n",
    "    return full_image_array\n",
    "\n",
    "# Load your model\n",
    "loaded_model = load_model('/content/drive/MyDrive/Working/models/attention_unet_model_62epoch_423_4.h5')\n",
    "\n",
    "# Directory path containing the images to test\n",
    "test_dir = '/content/drive/MyDrive/Working/Test/Mix'\n",
    "\n",
    "# Get list of image files and shuffle them randomly\n",
    "image_files = [f for f in os.listdir(test_dir) if f.endswith(('.jpeg', '.jpg', '.png'))]\n",
    "random.shuffle(image_files)  # Shuffle the list randomly\n",
    "\n",
    "# Define the output PDF file\n",
    "output_pdf_path = '/content/drive/MyDrive/Working/output_results.pdf'\n",
    "\n",
    "# Create a PdfPages object to save multiple pages to a single PDF\n",
    "with PdfPages(output_pdf_path) as pdf:\n",
    "    # Loop through the shuffled image files\n",
    "    for image_filename in image_files:\n",
    "        full_image_path = os.path.join(test_dir, image_filename)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        full_image = load_full_image(full_image_path)\n",
    "\n",
    "        # Predict the mask for the full image\n",
    "        predicted_mask = loaded_model.predict(full_image)[0, :, :, 0]  # Extract the 2D mask\n",
    "\n",
    "        # Apply threshold to get a binary mask\n",
    "        threshold = 0.5\n",
    "        predicted_mask_binary = (predicted_mask > threshold).astype(np.uint8)\n",
    "\n",
    "        # Plot the results for each image\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        # Display the original full image\n",
    "        axes[0].imshow(np.squeeze(full_image), cmap='gray')\n",
    "        axes[0].set_title(f'Full Image: {image_filename}')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # Display the predicted NV mask heatmap\n",
    "        im = axes[1].imshow(predicted_mask, cmap='jet', alpha=0.6)\n",
    "        axes[1].set_title('Predicted NV Heatmap')\n",
    "        axes[1].axis('off')\n",
    "        plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # Overlay predicted mask on the full image\n",
    "        axes[2].imshow(np.squeeze(full_image), cmap='gray')  # Original image\n",
    "        axes[2].imshow(predicted_mask_binary, cmap='jet', alpha=0.5)  # Predicted mask overlay\n",
    "        axes[2].set_title('Overlay: Full Image with Predicted Mask')\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        # Save the current figure to the PDF\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)  # Close the figure to save memory\n",
    "\n",
    "print(f\"Results saved to {output_pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNZPKpW5geFFXDSZE3cFSuW",
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
